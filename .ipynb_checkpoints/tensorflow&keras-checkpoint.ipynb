{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6249f0d5",
   "metadata": {},
   "source": [
    "### DEEP LEARNING and NEURAL NETWORK\n",
    "##### using teansorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07612ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a4b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train), (X_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4e7dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_trainF = X_train.reshape(len(X_train), 28*28)\n",
    "X_testF = X_test.reshape(len(X_test), 28*28)\n",
    "print(X_trainF.shape)\n",
    "X_trainF, X_testF = X_trainF/255, X_testF/255   ##scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed74a6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 10s 4ms/step - loss: 0.4674 - accuracy: 0.8770\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3034 - accuracy: 0.9149\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2826 - accuracy: 0.9208\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2732 - accuracy: 0.9237\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2664 - accuracy: 0.9258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x11b1a308610>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10, input_shape=(28*28,), activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(X_trainF, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40adee11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2645 - accuracy: 0.9255: 0s - loss: 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2644871473312378, 0.9254999756813049]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_testF, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5cdd9c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(X_test[200])\n",
    "np.argmax(model.predict(X_testF)[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9796a86f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11b2a6a51f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predicted = [np.argmax(i) for i in model.predict(X_testF)]\n",
    "cm = tf.math.confusion_matrix(labels=y_test, predictions=y_predicted)  ##confusionmatrix\n",
    "plt.imshow(cm, cmap='hot', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aefa67",
   "metadata": {},
   "source": [
    "tensorboard, Flattening and Scaling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02740cc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 15s 7ms/step - loss: 0.6649 - accuracy: 0.8303\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3431 - accuracy: 0.9045\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2950 - accuracy: 0.9175\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2652 - accuracy: 0.9255 0s - loss: 0.2655 - accura\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2428 - accuracy: 0.9315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x28b1066fee0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model2 = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.experimental.preprocessing.Rescaling(scale=1./255),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "])\n",
    "tb_callback = keras.callbacks.TensorBoard(log_dir=\"logs/SGD\",histogram_freq=1)\n",
    "model2.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model2.fit(X_train, y_train, epochs=5, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127296aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ea41a3",
   "metadata": {},
   "source": [
    "regularization with dropout layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daf9c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 27s 11ms/step - loss: 0.4628 - accuracy: 0.8611\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 20s 10ms/step - loss: 0.2476 - accuracy: 0.9287\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2059 - accuracy: 0.9423\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1824 - accuracy: 0.9481\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.1678 - accuracy: 0.95281s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x205f75fa5e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3 = keras.Sequential([\n",
    "    keras.layers.Dense(200,input_shape=(28*28,), activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model3.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model3.fit(X_trainF, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ca29043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 6ms/step - loss: 0.0887 - accuracy: 0.9732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08872417360544205, 0.9732000231742859]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_testF, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937951b",
   "metadata": {},
   "source": [
    "Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb68fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "##get trained model without the top layer. { ..../feature_vector}\n",
    "trainedModel = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "pretrainedLayer = hub.KerasLayer( trainedModel, input_shape=(224,224,3), trainable=False)\n",
    "\n",
    "\n",
    "newModel = keras.Sequential([\n",
    "    pretrainedLayer,\n",
    "    keras.layers.Dense(reqNoOfClasses)\n",
    "])\n",
    "newModel.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b0ac4",
   "metadata": {},
   "source": [
    " Convolution Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42cd205f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##cn is mainly used  in comp vision\n",
    "CNN = keras.Sequential([\n",
    "    ##cnn\n",
    "    keras.layers.Conv2D(filters=32,padding='valid', stride=(1,1) kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    ##dense\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "CNN.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eae23",
   "metadata": {},
   "source": [
    "data augmentation to prevent overfitting  \n",
    "in image processing with cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae343abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAugmLayer = keras.Sequential([\n",
    "    keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\",image_shape=()),\n",
    "    keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "    keras.layers.experimental.preprocessing.RandomRotation(0.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f856478",
   "metadata": {},
   "source": [
    "Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a045a19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  0],\n",
       "       [26, 10,  0],\n",
       "       [17, 13,  0],\n",
       "       [20, 16, 24],\n",
       "       [12, 29, 27],\n",
       "       [15,  3,  0],\n",
       "       [12, 29,  9],\n",
       "       [ 4, 19,  0],\n",
       "       [ 4, 22,  0],\n",
       "       [ 1, 14,  0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word embedding (using supervised technique)\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "reviews = ['nice food',\n",
    "          'amazing restaurant',\n",
    "          'too good',\n",
    "          'just loved it!',\n",
    "          'will go again',\n",
    "          'horrible food',\n",
    "          'never go there',\n",
    "          'poor service',\n",
    "          'poor quality',\n",
    "          'needs improvement']\n",
    "sentiment = np.array([1,1,1,1,1,0,0,0,0,0])\n",
    "\n",
    "vocab_size = 30\n",
    "max_length = 3\n",
    "encodedReviews = [one_hot(d, vocab_size) for d in reviews]\n",
    "paddedReviews = pad_sequences(encodedReviews, maxlen=max_length, padding='post')\n",
    "paddedReviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5babc744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3, 5)              150       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 166\n",
      "Trainable params: 166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embeded_vector_size = 5\n",
    "wrdModel = keras.Sequential()\n",
    "wrdModel.add(keras.layers.Embedding(vocab_size, embeded_vector_size, input_length=max_length, name='embedding'))\n",
    "wrdModel.add(keras.layers.Flatten())\n",
    "wrdModel.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "wrdModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "wrdModel.fit(paddedReviews, sentiment, epochs=50, verbose=0)\n",
    "print(wrdModel.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3003e31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 5\n",
      "embedding vector for nice - [ 0.02112724  0.09264202  0.05962163 -0.01154524 -0.0152463 ] and amazing- [ 0.08562744  0.00845588  0.01652019 -0.07925311 -0.0941014 ]\n",
      "embedding vector for horrible - [-0.09543003 -0.09601291 -0.05236762  0.09529765  0.03166131] and poor- [-0.0794685  -0.03294224 -0.04793671  0.08193892  0.00362636]\n"
     ]
    }
   ],
   "source": [
    "embeddingMat=wrdModel.get_layer('embedding').get_weights()[0]\n",
    "print(len(embeddingMat),len(embeddingMat[0]))\n",
    "\n",
    "print('embedding/feature vector for nice -',embeddingMat[3], 'and amazing-',embeddingMat[26])\n",
    "\n",
    "print('embedding/feature vector for horrible -',embeddingMat[15], 'and poor-',embeddingMat[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cf7f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26, 10]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot('amazing restaurant',30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "255e6e7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##word2vec [self-supervised learning]\n",
    "##!pip install gensim\n",
    "##!pip install python-Levenshtein\n",
    "\n",
    "import gensim\n",
    "review_text = df.reviewText.apply(gensim.utils.simple_preprocess)\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    ")\n",
    "model.build_vocab(review_text, progress_per=1000)\n",
    "model.train(review_text, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save(\"./word2vec-amazon-cell-accessories-reviews-short.model\")\n",
    "model.wv.most_similar(\"bad\")\n",
    "model.wv.similarity(w1=\"cheap\", w2=\"inexpensive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "475900c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## contextual sentence embedding for NLP\n",
    "## using BERT(Bidirectional Encoder Representations from Transformers)\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"\n",
    "\n",
    "bert_preprocess_model = hub.KerasLayer(preprocess_url)\n",
    "bert_encoder_model = hub.KerasLayer(encoder_url)\n",
    "\n",
    "def get_sentence_embeding(sentences):\n",
    "    preprocessed_text = bert_preprocess_model(sentences)\n",
    "    return bert_encoder_model(preprocessed_text)['pooled_output']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116b922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Functional Model\n",
    "\n",
    "#BERT Layers\n",
    "text_input = keras.layers.Input(shape=(), dtype=tf.string, name ='text')\n",
    "bert_model = get_sentence_embeding(text_input)\n",
    "\n",
    "#Neural Network layer\n",
    "L1 = keras.layers.Dropout(0.1, name='dropout')(bert_model)\n",
    "L2 = keras.layers.Dense(1, activation='sigmoid', name='output')(L1)\n",
    "\n",
    "rnnModel = keras.Model(inputs=[text_input], outputs=[L2])\n",
    "\n",
    "rnnModel.compile(optimizer='adam',\n",
    "                loss='binary_crossentropy',\n",
    "                metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c74cd0",
   "metadata": {},
   "source": [
    "Tensorflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab88d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "22\n",
      "-108\n",
      "31\n",
      "-1\n",
      "32\n",
      "34\n",
      "31\n",
      "\n",
      "21\n",
      "22\n",
      "-108\n"
     ]
    }
   ],
   "source": [
    "daily_sales = [21, 22, -108, 31, -1, 32, 34, 31]\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales)\n",
    "for sales in tf_dataset:\n",
    "    print(sales.numpy())\n",
    "print()\n",
    "for sales in tf_dataset.take(3):\n",
    "    print(sales.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3a56355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1512 1584 2304]\n",
      "[2448 2232 2232]\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tf_dataset.filter(lambda x:x>0).map(lambda y: y*72).shuffle(2).batch(3)\n",
    "for sales in tf_dataset.as_numpy_iterator():\n",
    "    print(sales)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
